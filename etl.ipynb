{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Processes\n",
    "Use this notebook to develop the ETL process for each of your tables before completing the `etl.py` file to load the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=guillaume password=test\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process `song_data`\n",
    "In this first part, you'll perform ETL on the first dataset, `song_data`, to create the `songs` and `artists` dimensional tables.\n",
    "\n",
    "Let's perform ETL on a single song file and load a single record into each table to start.\n",
    "- Use the `get_files` function provided above to get a list of all song JSON files in `data/song_data`\n",
    "- Select the first song in this list\n",
    "- Read the song file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_files = get_files('data/song_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACQT128F9331780.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACER128F4290F96.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACZK128F4243829.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACCG128F92E8A55.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACOW128F933E35F.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACHN128F1489601.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACLV128F427E123.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACNS128F14A2DF5.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACVS128E078BE39.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACPE128F421C1B9.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACSL128F93462F4.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACIW12903CC0F6D.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACFV128F935E50B.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACTB12903CAAF15.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAEF128F4273421.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAPK128E0786D96.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAVG12903CFA543.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAADZ128F9348C2E.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAABD128F429CF47.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAMQ128F1460CD3.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAARJ128F9320760.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAMO128F1481E7F.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAVO128F93133D4.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAFD128F92F423A.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/A/TRAAAAW128F429D538.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABVM128F92CA9DC.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABXG128F9318EBD.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABJV128F1460C49.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABNV128F425CEE1.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABRB128F9306DD5.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABYW128F4244559.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABYN12903CFD305.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABLR128F423B7E3.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABDL12903CAABBA.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABCL128F4286650.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/B/TRAABJL12903CDCF1A.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCRU128F423F449.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCUQ128E0783E2B.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCEI128F424C983.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCFL128F149BB0D.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCAJ12903CDFCC2.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCTK128F934B224.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCEC128F426456E.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCPZ128F4275C32.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCXB128F4286BD3.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCIX128F4265903.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCKL128F423A778.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/C/TRABCYE128F934CE1D.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABACN128F425B784.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAXR128F426515F.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAZH128F930419A.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAIO128F42938F9.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAVQ12903CBF7E0.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAXL128F424FC50.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAXV128F92F6AE3.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABATO128F42627E9.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAFP128F931E9A1.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAFJ128F42AF24E.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/A/TRABAWW128F4250A31.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBBV128F42967D7.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBTA128F933D304.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBXU128F92FEF48.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBVJ128F92F7EAA.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBAM128F429D223.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBKX128F4285205.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBJE12903CDB442.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBLU128F93349CF.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBZN12903CD9297.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBOR128F4286200.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBOP128F931B50D.json',\n",
       " '/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/B/B/TRABBNP128F932546F.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/song_data/A/A/C/TRAACQT128F9331780.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(song_files[0], typ='series')\n",
    "df = df.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_songs</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR1Y2PT1187FB5B9CE</td>\n",
       "      <td>27.94017</td>\n",
       "      <td>-82.32547</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>John Wesley</td>\n",
       "      <td>SOLLHMX12AB01846DC</td>\n",
       "      <td>The Emperor Falls</td>\n",
       "      <td>484.62322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_songs           artist_id artist_latitude artist_longitude  \\\n",
       "0         1  AR1Y2PT1187FB5B9CE        27.94017        -82.32547   \n",
       "\n",
       "  artist_location  artist_name             song_id              title  \\\n",
       "0         Brandon  John Wesley  SOLLHMX12AB01846DC  The Emperor Falls   \n",
       "\n",
       "    duration year  \n",
       "0  484.62322    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1: `songs` Table\n",
    "#### Extract Data for Songs Table\n",
    "- Select columns for song ID, title, artist ID, year, and duration\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `song_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = df.loc[0,['song_id', 'title', 'artist_id', 'year', 'duration']]\n",
    "song_data = song_data.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Record into Song Table\n",
    "Implement the `song_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song into the `songs` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songs` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(song_table_insert, song_data)\n",
    "    conn.commit()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2: `artists` Table\n",
    "#### Extract Data for Artists Table\n",
    "- Select columns for artist ID, name, location, latitude, and longitude\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `artist_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_data = df.loc[0,['artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']]\n",
    "artist_data = artist_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AR1Y2PT1187FB5B9CE', 'John Wesley', 'Brandon', 27.94017, -82.32547]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Record into Artist Table\n",
    "Implement the `artist_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song's artist into the `artists` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `artists` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nINSERT INTO artists (artist_id, artist_name, artist_location, artist_latitude, artist_longitude)\\nVALUES (%s, %s, %s, %s, %s)\\nON CONFLICT (artist_id)\\nDO NOTHING\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_table_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur.execute(artist_table_insert, artist_data)\n",
    "    conn.commit()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process `log_data`\n",
    "In this part, you'll perform ETL on the second dataset, `log_data`, to create the `time` and `users` dimensional tables, as well as the `songplays` fact table.\n",
    "\n",
    "Let's perform ETL on a single log file and load a single record into each table.\n",
    "- Use the `get_files` function provided above to get a list of all log JSON files in `data/log_data`\n",
    "- Select the first log file in this list\n",
    "- Read the log file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = get_files('data/log_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = log_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/documents/data/udacity/data_engineering/data_modelisation/projects/data_modeling_postgres/data/log_data/2018/11/2018-11-13-events.json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(filepath, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 394 entries, 0 to 393\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   artist         339 non-null    object \n",
      " 1   auth           394 non-null    object \n",
      " 2   firstName      383 non-null    object \n",
      " 3   gender         383 non-null    object \n",
      " 4   itemInSession  394 non-null    int64  \n",
      " 5   lastName       383 non-null    object \n",
      " 6   length         339 non-null    float64\n",
      " 7   level          394 non-null    object \n",
      " 8   location       383 non-null    object \n",
      " 9   method         394 non-null    object \n",
      " 10  page           394 non-null    object \n",
      " 11  registration   383 non-null    float64\n",
      " 12  sessionId      394 non-null    int64  \n",
      " 13  song           339 non-null    object \n",
      " 14  status         394 non-null    int64  \n",
      " 15  ts             394 non-null    int64  \n",
      " 16  userAgent      383 non-null    object \n",
      " 17  userId         394 non-null    object \n",
      "dtypes: float64(2), int64(4), object(12)\n",
      "memory usage: 55.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3: `time` Table\n",
    "#### Extract Data for Time Table\n",
    "- Filter records by `NextSong` action\n",
    "- Convert the `ts` timestamp column to datetime\n",
    "  - Hint: the current timestamp is in milliseconds\n",
    "- Extract the timestamp, hour, day, week of year, month, year, and weekday from the `ts` column and set `time_data` to a list containing these values in order\n",
    "  - Hint: use pandas' [`dt` attribute](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html) to access easily datetimelike properties.\n",
    "- Specify labels for these columns and set to `column_labels`\n",
    "- Create a dataframe, `time_df,` containing the time data for this file by combining `column_labels` and `time_data` into a dictionary and converting this into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.page == 'NextSong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.page == 'NextSong']\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['ts'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.to_datetime(df['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(df['datetime'].dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = []\n",
    "time_data.extend((df['ts'],\n",
    "                       df['datetime'].dt.hour,\n",
    "                       df['datetime'].dt.day,\n",
    "                       df['datetime'].dt.isocalendar().week,\n",
    "                       df['datetime'].dt.month,\n",
    "                       df['datetime'].dt.year,\n",
    "                       df['datetime'].dt.weekday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = ['timestamp','hour', 'day', 'week', 'month', 'year', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}\n",
    "for k, v in zip(column_labels, time_data):\n",
    "    time_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1542069637796</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1542071549796</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1542079142796</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1542081112796</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1542085206796</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  hour  day  week  month  year  weekday\n",
       "1  1542069637796     0   13    46     11  2018        1\n",
       "3  1542071549796     1   13    46     11  2018        1\n",
       "4  1542079142796     3   13    46     11  2018        1\n",
       "5  1542081112796     3   13    46     11  2018        1\n",
       "8  1542085206796     5   13    46     11  2018        1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df = pd.DataFrame(time_dict)\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in time_df.iterrows():\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(time_df.iterrows())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Records into Time Table\n",
    "Implement the `time_table_insert` query in `sql_queries.py` and run the cell below to insert records for the timestamps in this log file into the `time` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `time` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nINSERT INTO time (start_time, hour, day, week, month, year, weekday)\\nVALUES (%s, %s, %s, %s, %s, %s, %s)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_table_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i, row in time_df.iterrows():\n",
    "        cur.execute(time_table_insert, list(row))\n",
    "        conn.commit()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4: `users` Table\n",
    "#### Extract Data for Users Table\n",
    "- Select columns for user ID, first name, last name, gender and level and set to `user_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Josh Groban</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kate</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>Harrell</td>\n",
       "      <td>244.45342</td>\n",
       "      <td>paid</td>\n",
       "      <td>Lansing-East Lansing, MI</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540473e+12</td>\n",
       "      <td>537</td>\n",
       "      <td>Petit Papa Noel (Album Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1542129654796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>97</td>\n",
       "      <td>2018-11-13 17:20:54.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>22-20s</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Sara</td>\n",
       "      <td>F</td>\n",
       "      <td>67</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>237.16526</td>\n",
       "      <td>paid</td>\n",
       "      <td>Winston-Salem, NC</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540809e+12</td>\n",
       "      <td>411</td>\n",
       "      <td>Such A Fool</td>\n",
       "      <td>200</td>\n",
       "      <td>1542152631796</td>\n",
       "      <td>\"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like...</td>\n",
       "      <td>95</td>\n",
       "      <td>2018-11-13 23:43:51.796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist       auth firstName gender  itemInSession lastName  \\\n",
       "210  Josh Groban  Logged In      Kate      F             15  Harrell   \n",
       "389       22-20s  Logged In      Sara      F             67  Johnson   \n",
       "\n",
       "        length level                  location method      page  registration  \\\n",
       "210  244.45342  paid  Lansing-East Lansing, MI    PUT  NextSong  1.540473e+12   \n",
       "389  237.16526  paid         Winston-Salem, NC    PUT  NextSong  1.540809e+12   \n",
       "\n",
       "     sessionId                             song  status             ts  \\\n",
       "210        537  Petit Papa Noel (Album Version)     200  1542129654796   \n",
       "389        411                      Such A Fool     200  1542152631796   \n",
       "\n",
       "                                             userAgent userId  \\\n",
       "210  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     97   \n",
       "389  \"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like...     95   \n",
       "\n",
       "                   datetime  \n",
       "210 2018-11-13 17:20:54.796  \n",
       "389 2018-11-13 23:43:51.796  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>Cecilia</td>\n",
       "      <td>Owens</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Wyatt</td>\n",
       "      <td>Scott</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>55</td>\n",
       "      <td>Martin</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>95</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>14</td>\n",
       "      <td>Theodore</td>\n",
       "      <td>Harris</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id first_name last_name gender level\n",
       "65        6    Cecilia     Owens      F  free\n",
       "4         9      Wyatt     Scott      M  free\n",
       "355      55     Martin   Johnson      M  free\n",
       "270      95       Sara   Johnson      F  paid\n",
       "106      14   Theodore    Harris      M  free"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = df[['userId', 'firstName', 'lastName', 'gender', 'level']]\n",
    "user_df.columns = ['user_id', 'first_name', 'last_name', 'gender', 'level']\n",
    "user_df = user_df.drop_duplicates()\n",
    "user_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Records into Users Table\n",
    "Implement the `user_table_insert` query in `sql_queries.py` and run the cell below to insert records for the users in this log file into the `users` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `users` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in user_df.iterrows():\n",
    "    cur.execute(user_table_insert, row)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5: `songplays` Table\n",
    "#### Extract Data and Songplays Table\n",
    "This one is a little more complicated since information from the songs table, artists table, and original log file are all needed for the `songplays` table. Since the log file does not specify an ID for either the song or the artist, you'll need to get the song ID and artist ID by querying the songs and artists tables to find matches based on song title, artist name, and song duration time.\n",
    "- Implement the `song_select` query in `sql_queries.py` to find the song ID and artist ID based on the title, artist name, and duration of a song.\n",
    "- Select the timestamp, user ID, level, song ID, artist ID, session ID, location, and user agent and set to `songplay_data`\n",
    "\n",
    "#### Insert Records into Songplays Table\n",
    "- Implement the `songplay_table_insert` query and run the cell below to insert records for the songplay actions in this log file into the `songplays` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songplays` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns : artist, length, song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     for index, row in df.iterrows():\n",
    "#         # get songid and artistid from song and artist tables\n",
    "#         cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "#         results = cur.fetchone()\n",
    "#         print(results)\n",
    "# except psycopg2.Error as e: \n",
    "#     print(\"Error: Inserting Rows\")\n",
    "#     print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "artist                                                          Fu\n",
      "auth                                                     Logged In\n",
      "firstName                                                    Kevin\n",
      "gender                                                           M\n",
      "itemInSession                                                    1\n",
      "lastName                                                  Arellano\n",
      "length                                                   280.05832\n",
      "level                                                         free\n",
      "location                                   Harrisburg-Carlisle, PA\n",
      "method                                                         PUT\n",
      "page                                                      NextSong\n",
      "registration                                       1540006905796.0\n",
      "sessionId                                                      514\n",
      "song                                                       Ja I Ty\n",
      "status                                                         200\n",
      "ts                                                   1542069637796\n",
      "userAgent        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...\n",
      "userId                                                          66\n",
      "datetime                                2018-11-13 00:40:37.796000\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index)\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ja I Ty\n",
      "A Party Song (The Walk of Shame)\n",
      "Pop-Pop!\n",
      "C'mon N' Ride It (The Train) (LP Version)\n",
      "Born To Lead\n",
      "The Pretender\n",
      "Side .002\n",
      "Too Late For Goodbyes\n",
      "Sister Twisted\n",
      "Ever So Sweet\n",
      "9 Crimes (Demo)\n",
      "Crying Blue Rain\n",
      "Peito Vazio\n",
      "Lady D'Arbanville\n",
      "You're The One\n",
      "Do You Hear The People Sing?\n",
      "Work To Do\n",
      "When A Woman Cries\n",
      "Till The Sky Falls Down\n",
      "Sealed With A Kiss\n",
      "Your Touch\n",
      "Circles (2007 Live At The Moore Theater in Seattle LP Version)\n",
      "Howlin\u0019 For You\n",
      "This Is Your Life\n",
      "Fingers And Thumbs (Cold Summer's Day) (Sound Factory Remix)\n",
      "Snow [Hey Oh] (Album Version)\n",
      "Bulgarian  Chicks\n",
      "Tiger Mountain Peasant Song\n",
      "Man With Bindle [Pawt 1] (2004)\n",
      "Sehr kosmisch\n",
      "Over And Over\n",
      "Break The Night With Colour\n",
      "Chemistry\n",
      "The Sun In The Stream\n",
      "Mockingbird\n",
      "Love Walks In (Remastered Album Version)\n",
      "Never Alone (Acoustic Version)\n",
      "Way Out of Here [Album Version]\n",
      "Beautiful Dangerous (featuring Fergie)\n",
      "Alejandro\n",
      "Never Ever\n",
      "Who I Am\n",
      "Pequenos Olhos\n",
      "The Fear You Won't Fall\n",
      "Revelry\n",
      "Rock 'n' Roll Creation\n",
      "Beside You In Time\n",
      "Breathless (Album Version)\n",
      "Citizen Erased\n",
      "Something About Mary\n",
      "She's In It for the Money\n",
      "Do I\n",
      "Walk A Little Straighter\n",
      "DVNO\n",
      "Ain't Misbehavin\n",
      "Don't Cry (Original)\n",
      "Changeling\n",
      "American Life [Headcleanr Rock Mix]\n",
      "First Dance\n",
      "Invincible\n",
      "Falling Through Your Clothes\n",
      "Rain\n",
      "You're No Good (Album Version)\n",
      "Anyway You Choose To Give It (Radio Edit)\n",
      "Jackie\n",
      "Long Black Road\n",
      "Resistance\n",
      "Creil City\n",
      "Interlude #1 (Mama)\n",
      "One Day In Your Life\n",
      "The Final Countdown\n",
      "Summertime (Album Version)\n",
      "Good Love Is On The Way\n",
      "Shelter\n",
      "Nantes\n",
      "My sweet shadow\n",
      "Lubumba '98\n",
      "Yellow\n",
      "Siulil A Run\n",
      "Silence\n",
      "Blues Stay Away From Me\n",
      "Unwell (Album Version)\n",
      "Sinisten tÃÂ¤htien alla\n",
      "Move The Crowd\n",
      "Overboard\n",
      "FAI Piss-Up 1\n",
      "Money Ain't A Thang\n",
      "Bring 'Em Back\n",
      "Morning Sky\n",
      "Plus Ones\n",
      "Cold Desert\n",
      "Neighborhood #1 (Tunnels)\n",
      "Safety Dance\n",
      "Bin Laden Feat. MosDef (Inst)\n",
      "Pleasure And Pain\n",
      "Prologue\n",
      "Hey There Delilah\n",
      "Blow Me Away\n",
      "Perpetuum Mobile\n",
      "Revelry\n",
      "Di Terra (2006 Digital Remaster)\n",
      "Real Life\n",
      "Engel\n",
      "Noche De AcciÃÂ³n\n",
      "Jeez Louise (Album)\n",
      "Flashing Lights\n",
      "Use Somebody\n",
      "Underscore\n",
      "Be Somebody\n",
      "En resa\n",
      "Skinny Love\n",
      "Television Rules The Nation / Crescendolls\n",
      "Be By Myself\n",
      "Freedumb\n",
      "A Thousand Tiny Pieces\n",
      "Half Of My Heart\n",
      "Missing\n",
      "Revelry\n",
      "Hey Girl\n",
      "ÃÂ Noite\n",
      "Courage\n",
      "Awake\n",
      "Me Pregunto\n",
      "Monkey's Paw\n",
      "Disease (Album Version)\n",
      "Movin' On Up\n",
      "Shoh-ka\n",
      "Independence Day (version)\n",
      "Y Quisiera\n",
      "Horn Concerto No. 4 in E flat K495: II. Romance (Andante cantabile)\n",
      "Early 70's Gymnastics\n",
      "Victoria (LP Version)\n",
      "Wake Up\n",
      "Hard Rock Bottom Of Your Heart (Single Remix Remastered Version)\n",
      "Paper Planes\n",
      "Last Nite\n",
      "Let There Be Light (album version)\n",
      "When You Were Young\n",
      "What's Happenin'\n",
      "Sympathy For The Devil\n",
      "Smile\n",
      "Time To Pretend\n",
      "Sea Ghost\n",
      "Papa's Home\n",
      "Afterlife\n",
      "Dub The Frequencies Of Love\n",
      "Do It ('Til You're Satisfied)\n",
      "She's So High\n",
      "Le Jardin d'Hiver\n",
      "Fire Coming Out Of The Monkey's Head\n",
      "Ready_ Steady_ Go (Album Version)\n",
      "Better Off Dead\n",
      "Boys Will Be Boys\n",
      "Hey_ Soul Sister\n",
      "My Perfect Cousin\n",
      "God Is On The Radio\n",
      "Between The Bars\n",
      "Seven Nation Army\n",
      "Signals Over The Air\n",
      "Susanne\n",
      "Sexy Eyes\n",
      "You're The One\n",
      "La Otra Princesa\n",
      "McFearless\n",
      "Rayando el sol\n",
      "Genom tunna tyger\n",
      "Cards & Quarters\n",
      "Bulletproof\n",
      "Seerosenteich\n",
      "Ripped To Shreds (feat. Vinnie Paz_ Celph Titled & Demoz)\n",
      "Push The Feeling On\n",
      "Say Back Something\n",
      "Careful (Album Version)\n",
      "Guys Like Me\n",
      "Petit Papa Noel (Album Version)\n",
      "Good Directions\n",
      "Shiny & New\n",
      "Kun Puut Tekee SeittiÃÂ¤\n",
      "Mama Tierra\n",
      "M1 A1\n",
      "Slang Blade\n",
      "Aberinkula\n",
      "Time To Pretend\n",
      "Don't Stop At The Top\n",
      "Not An Addict\n",
      "Human\n",
      "Suspicious Minds\n",
      "Good Things\n",
      "Moon And Moon\n",
      "If I Had You\n",
      "Sayonara-Nostalgia\n",
      "No No No\n",
      "Passenger\n",
      "You And Me Jesus\n",
      "So Pray (Genuine Album Version)\n",
      "Girl U Want (Live)\n",
      "Blame It on My Youth (From \"Let's Get Lost\")\n",
      "Sympathy For The Devil\n",
      "You're The One\n",
      "Rubberband Man\n",
      "Suzy 2003 (Live)\n",
      "Mise En Bouche\n",
      "Ron's Victory (\"Harry Potter & The Half-Blood Prince\")\n",
      "I'm Goin In\n",
      "Something New\n",
      "I'm Yours / Somewhere Over The Rainbow (EP Version)\n",
      "So Long_ Marianne\n",
      "The Modern Age\n",
      "Moon River (Live) (Album Version)\n",
      "Como La Flor (2005 Re-mastering) (Live)\n",
      "Come As You Are\n",
      "Heartbreaker\n",
      "Pink\n",
      "Chase Dem\n",
      "My Heart's Got A Memory\n",
      "Here I Am (Album Version)\n",
      "Boombastic\n",
      "Le Jardin d'Hiver\n",
      "Het Nummer Van God\n",
      "TE QUIERO PUTA!\n",
      "Ripping Flesh\n",
      "Tive Sim\n",
      "Fortunate Fool\n",
      "Whistlin' Past The Graveyard\n",
      "Bubbly\n",
      "Yellow\n",
      "Doomed Now\n",
      "Secrets\n",
      "16 Candles\n",
      "Spotlight\n",
      "Uprising\n",
      "Vanilla Twilight\n",
      "The New Year\n",
      "Road to Kaintuck\n",
      "Dream Catch Me\n",
      "Uncle Jam\n",
      "When The Smoke Is Going Down\n",
      "Secrets\n",
      "In League With Satan\n",
      "Home\n",
      "Sam_ As In Samantha\n",
      "Crazy\n",
      "Different Kind Of Fine (Album)\n",
      "Bandelero\n",
      "Wrong Turn\n",
      "Bad Moon Rising\n",
      "Here_ There And Everywhere\n",
      "Estoy Enamorado De Ella (Salsa)\n",
      "The Trance Is The Motion [Live]\n",
      "Ain't No Rest For The Wicked (Original Version)\n",
      "Musti Sotakoira (2007 Digital Remaster)\n",
      "Le Jardin d'Hiver\n",
      "Sweet Soul Music (Single/LP Version)\n",
      "Stranger than Fiction\n",
      "Le Moulin\n",
      "I Stand Corrected (Album)\n",
      "Undo\n",
      "Venus\n",
      "Snow [Hey Oh] (Album Version)\n",
      "We Who Wait (Single)\n",
      "Sweet Darlin'\n",
      "Dog Days Are Over (Radio Edit)\n",
      "The Bed's Too Big Without You\n",
      "Time and Space\n",
      "In The Meantime (LP Version)\n",
      "Vanilla Twilight\n",
      "Too Drunk to Fuck\n",
      "No More Fun And Games\n",
      "Cudi Zone\n",
      "Danse Pour Moi\n",
      "Flashing Lights\n",
      "Canada\n",
      "Encore Break\n",
      "Lovely Ladies\n",
      "Danke Schoen\n",
      "Bulls On Parade\n",
      "Love Me Girl\n",
      "Recado Falado (MetrÃÂ´ Da Saudade)\n",
      "Hey There Delilah\n",
      "Pretty Wings\n",
      "The Sound of Settling (Album Version)\n",
      "Bottom of a Bottle (Explicit Album Version)\n",
      "You'll Be In My Heart\n",
      "The Rhythm Of The Night\n",
      "Summer Child\n",
      "End Of The Road\n",
      "Boy Meets Girl (And Vice Versa)\n",
      "BedRock (Radio Edit) (feat.Lloyd)\n",
      "Good Day\n",
      "Hang On In There Baby\n",
      "Call It Off (Album Version)\n",
      "Dimmer Light\n",
      "Dig This Well Deep\n",
      "Toranj\n",
      "Love Letter To Japan\n",
      "Hullu mies hullu\n",
      "New Divide (Album Version)\n",
      "Mrs. Officer\n",
      "Video Killed The Radio Star\n",
      "La Muy_ Muy\n",
      "Fuck Kitty\n",
      "Afortunada\n",
      "This Is Your Life\n",
      "Drop The World\n",
      "Move Along\n",
      "Confessions\n",
      "Faberge Falls For Shuggie\n",
      "The Star Shines\n",
      "Driver's Seat\n",
      "Say (All I Need)\n",
      "Breakdown\n",
      "..Come Around\n",
      "Dirty Little Secret\n",
      "Find The Reason (Album Version)\n",
      "Coin-Operated Boy\n",
      "Bitter Sweet Symphony\n",
      "Cold Blooded (Acid Cleanse)\n",
      "Then\n",
      "Clobberin' Time\n",
      "Why Don't You Find Out For Yourself\n",
      "Home\n",
      "Forgive Me\n",
      "Tales Of Brave Ulysses\n",
      "Halo\n",
      "Become Yourself\n",
      "Another F.U. Song (Album)\n",
      "Eat To Live (Amended Version)\n",
      "No Child Of Mine\n",
      "Goodnight Girl\n",
      "All In\n",
      "Mamma\n",
      "Undo\n",
      "Where Do The Children Play?\n",
      "Me Voy A Ir\n",
      "Such A Fool\n",
      "Love Can Damage Your Health\n",
      "The Ghost Of Old Bull Lee\n",
      "Canada\n",
      "Ten Commandments (Amended Version)\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "\n",
    "    # get songid and artistid from song and artist tables\n",
    "    cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "    results = cur.fetchone()\n",
    "    print(row.song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "\n",
    "    # get songid and artistid from song and artist tables\n",
    "    cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "    results = cur.fetchone()\n",
    "    \n",
    "    if results:\n",
    "        songid, artistid = results\n",
    "    else:\n",
    "        songid, artistid = None, None\n",
    "\n",
    "    # insert songplay record\n",
    "    # timestamp, user ID, level, song ID, artist ID, session ID, location, and user agent \n",
    "    songplay_data = (index, row.ts, row.userId, row.level, songid, artistid, row.sessionId, row.location, row.userAgent)\n",
    "    cur.execute(songplay_table_insert, songplay_data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Connection to Sparkify Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement `etl.py`\n",
    "Use what you've completed in this notebook to implement `etl.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
